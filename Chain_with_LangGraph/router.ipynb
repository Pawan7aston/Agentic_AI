{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  What is a Router?\n",
    "\n",
    "In LangGraph, a **Router** is a **decision-making node** that looks at the incoming **messages** (or some state) and decides **where the flow should go next** in the graph.\n",
    "\n",
    "Think of it as a **switchboard**:\n",
    "\n",
    "* You have multiple possible paths (nodes/tools/subgraphs).\n",
    "* The Router inspects the input (like the last `AIMessage`).\n",
    "* It routes control to the correct branch.\n",
    "\n",
    "---\n",
    "\n",
    "##  Why do we need a Router?\n",
    "\n",
    "When building agentic systems:\n",
    "\n",
    "1. The **Chat Model** may not always just “answer in text.”\n",
    "   It may decide to:\n",
    "\n",
    "   * Call a **tool** (e.g., query database).\n",
    "   * Call a **different model** (e.g., reasoning LLM vs. summarization LLM).\n",
    "   * Hand control back to the **user**.\n",
    "2. Instead of hardcoding `if/else`, LangGraph lets you define a **Router node**.\n",
    "\n",
    "---\n",
    "\n",
    "##  How Router Works with Messages, Model, Tools\n",
    "\n",
    "1. **Messages arrive** (list of `HumanMessage`, `AIMessage`, `ToolMessage`).\n",
    "2. **Router logic** inspects the latest message:\n",
    "\n",
    "   * If it has a `tool_calls` or `function_call` → route to tool executor.\n",
    "   * If plain text → route to final output node.\n",
    "   * If metadata suggests “use another model” → route accordingly.\n",
    "3. After the routed node finishes, the result gets appended as a new message and control comes back into the graph.\n",
    "\n",
    "---\n",
    "\n",
    "##  Example (simplified)\n",
    "\n",
    "```python\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\").bind_tools([])\n",
    "\n",
    "def router(state):\n",
    "    last_msg = state[\"messages\"][-1]\n",
    "    if isinstance(last_msg, AIMessage) and last_msg.additional_kwargs.get(\"function_call\"):\n",
    "        return \"tool_executor\"     # route to tool\n",
    "    return \"final_output\"          # route to output\n",
    "\n",
    "# Graph definition\n",
    "workflow = StateGraph(dict)\n",
    "workflow.add_node(\"model\", llm)\n",
    "workflow.add_node(\"tool_executor\", lambda s: {\"messages\": [\"Tool ran.\"]})\n",
    "workflow.add_node(\"final_output\", lambda s: {\"messages\": [\"Done.\"]})\n",
    "\n",
    "workflow.add_edge(\"model\", \"router\", condition=router)\n",
    "workflow.add_edge(\"tool_executor\", END)\n",
    "workflow.add_edge(\"final_output\", END)\n",
    "```\n",
    "\n",
    "Here:\n",
    "\n",
    "* **Chat Model** generates an `AIMessage`.\n",
    "* **Router** inspects whether it’s a tool call or plain text.\n",
    "* Based on that, the graph routes to either `tool_executor` or `final_output`.\n",
    "\n",
    "---\n",
    "\n",
    "## Router vs Chat Model\n",
    "\n",
    "* **Chat Model** = “brain” (generates next step suggestion).\n",
    "* **Router** = “traffic cop” (interprets that suggestion and decides the execution path).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6 (default, Apr 30 2025, 02:07:17) \n[Clang 17.0.0 (clang-1700.0.13.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
